{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recogniser"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For this project, a series of 28 x 28 pixel images showing handwritten digits will be classified into their corresponding labels using a convolutional neural network created using Keras. Despite initially considering taking more data, I came to realise the training data from keras.datasets was exactly the same length as the data from Kaggle making me think they could be the same. For future reference however, always attempt to find more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from scipy.stats import mode\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "(42000, 784)\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    4\n",
      "4    0\n",
      "Name: label, dtype: int64\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./digit-recognizer/train.csv',delimiter=',')\n",
    "test_data = pd.read_csv('./digit-recognizer/test.csv',delimiter=',')\n",
    "# print(len(test_data))\n",
    "train_labels = train_data['label']\n",
    "train_data = train_data.drop(['label'],axis=1)\n",
    "print(train_data.head())\n",
    "print(train_data.shape)\n",
    "print(train_labels.head())\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to determine whether or not there are any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       784\n",
      "unique        1\n",
      "top       False\n",
      "freq        784\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "null_values = train_data.isnull().any().describe()\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape to include grayscale dimension. 3bytes required for rgb!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy().reshape((42000,28,28,1))\n",
    "test_data = test_data.to_numpy().reshape((28000,28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode target variable is not a must when you use a multiclass classification. It depends on the loss function you use. If you don't want to encode target variable, you must use sparsecategoricalcrossentropy as loss function. Otherwise, you use categorical_crossentropy as loss function and you have to encode target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train_labels,num_classes=10)\n",
    "print(train_labels[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train_data[:5000]\n",
    "train_data = train_data[5000:len(train_data)+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to add random geomtric transformations to each image. This will transform the data and replace it on every epoch and will guarantee better generalisation. The transformations used can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(train_data)\n",
    "val_labels = train_labels[:5000]\n",
    "train_labels = train_labels[5000:len(train_labels)+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a GPU I'd create many more variations of these models and throw them together in an ensemble. But unforunately, I barely have enough processing power to make them overfit. CNN's are notoriously large models also. For this reason I've stuck with 3 models but know for a fact I'd get improved results with a larger model.\n",
    "\n",
    "In a regular neural net each layer for this particular project would have 28*28*1(for grayscale) neurons. This is not scalable when considering much larger picture which need classifying. This is why convolutional layers are used which find local patterns rather than global patterns. Depending on the Kernel size used (which i have varied in my ensemble to find different patterns) it will look for patterns in windows of this many pixels. After learning these patterns they can recognise it again anywhere. The higher layers learn small patterns such as edges or corners where as the lower layers in a Conv net learn the largest patterns as pooling occurs by learning patterns made up of smaller features learnt in the upper layers. Commonly referred to as a spatial hierarchy. \n",
    "\n",
    "They operate over 3D tensors called feature maps which includes the x,y and depth/channel axis (grayscale). This depth axis is 3 bytes for a colour drawing. Convolution extracts patches of size kernel_size, applies same operation. A 28x28x1 input feature map with 32 channels/filters and a 3x3 kernel_size will have a 26x26x32 output feature map. The 26x26 grid represents response map of the filter at different locations of the input. This means every dimension of the depth axis is a feature / filter and so the number of filters chosen represents the number of features that can be learnt by each layers.\n",
    "\n",
    "Response map - 2D map of presence of feature at different locations of input.\n",
    "\n",
    "Hyperparameters that required tuning\n",
    "kernel_size = 5x5, 4x4, 3x3\n",
    "Depth / number of filters - picking too many can result in overfiltering\n",
    "\n",
    "The conv net slides the kernel across the 3D input stopping at every possible location extracting 3D output of surrounding features. This output is then transformed via tensor product with weight matrix into a 1D vector the same shape as the output length. They are then reassembled into a new 3D tensor output map. Location between input and output tensors remains consistent.\n",
    "\n",
    "Ouput and input widths and heights differ for 2 reasons.\n",
    "\n",
    "-border effects (countered by padding the input)\n",
    "-using strides\n",
    "\n",
    "adding padding ensures you can center convolution windows around each element. it can take the following values\n",
    "\n",
    "1) \"valid\" - no padding\n",
    "2) \"same\" - pad so output has same width and height of input\n",
    "\n",
    "stride is the distance between 2 windows. this downsizes the output feature map\n",
    "Maxpooling is often used instead which will find the maximum value of an nxn pool and stride to the next location by n. this will rapidly shrink the layers and consequently increase the size of the features the next layer can find thus it will allow learning of a spatial hierarchy. Without downsampling, the features found will be virtually the same as the high level layers and there will not be much point. Additionally when coupling a large final feature map with a Dense layer of 256 you'll be left with far too many parameters to calculate which would lead to overfitting. I could also have used average pooling but maxpooling supposedly gives better results.\n",
    "\n",
    "Batch normalization allows for easier generalisation and less over fitting. It adaptively normalizes data, mean and variance over time during training allowing for easier gradient propagation and deeper networks.\n",
    "\n",
    "I additionally toyed with the idea of using depthwise separable conv layer. These lightweight layers are sometimes considered a good and more efficient alternative to normal conv2d layers. However, directly substituting for conv2d layers made for more volatile validation accuracy and and overall lower percentage accuracy. So I subbed the conv2d layers back in.\n",
    "\n",
    "I used matplotlib to plot val acc against epochs to determine where the models overfit.\n",
    "\n",
    "Learning rate reduction speaks for itself, as the minima is reached, the learning rate is reduced so as to not overshoot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/30\n",
      " - 402s - loss: 0.2211 - acc: 0.9304 - val_loss: 0.0825 - val_acc: 0.9734\n",
      "Epoch 2/30\n",
      " - 417s - loss: 0.0783 - acc: 0.9768 - val_loss: 0.0390 - val_acc: 0.9884\n",
      "Epoch 3/30\n",
      " - 401s - loss: 0.0643 - acc: 0.9801 - val_loss: 0.0524 - val_acc: 0.9836\n",
      "Epoch 4/30\n",
      " - 432s - loss: 0.0545 - acc: 0.9830 - val_loss: 0.0329 - val_acc: 0.9896\n",
      "Epoch 5/30\n",
      " - 458s - loss: 0.0527 - acc: 0.9835 - val_loss: 0.0258 - val_acc: 0.9912\n",
      "Epoch 6/30\n",
      " - 397s - loss: 0.0449 - acc: 0.9862 - val_loss: 0.0400 - val_acc: 0.9872\n",
      "Epoch 7/30\n",
      " - 395s - loss: 0.0430 - acc: 0.9873 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Epoch 8/30\n",
      " - 394s - loss: 0.0410 - acc: 0.9877 - val_loss: 0.0413 - val_acc: 0.9872\n",
      "Epoch 9/30\n",
      " - 394s - loss: 0.0391 - acc: 0.9886 - val_loss: 0.0214 - val_acc: 0.9928\n",
      "Epoch 10/30\n",
      " - 397s - loss: 0.0359 - acc: 0.9892 - val_loss: 0.0176 - val_acc: 0.9944\n",
      "Epoch 11/30\n",
      " - 395s - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0399 - val_acc: 0.9896\n",
      "Epoch 12/30\n",
      " - 394s - loss: 0.0333 - acc: 0.9892 - val_loss: 0.0205 - val_acc: 0.9936\n",
      "Epoch 13/30\n",
      " - 397s - loss: 0.0301 - acc: 0.9908 - val_loss: 0.0205 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/30\n",
      " - 440s - loss: 0.0222 - acc: 0.9933 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "Epoch 15/30\n",
      " - 446s - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0148 - val_acc: 0.9960\n",
      "Epoch 16/30\n",
      " - 401s - loss: 0.0196 - acc: 0.9943 - val_loss: 0.0178 - val_acc: 0.9946\n",
      "Epoch 17/30\n",
      " - 398s - loss: 0.0211 - acc: 0.9934 - val_loss: 0.0182 - val_acc: 0.9946\n",
      "Epoch 18/30\n",
      " - 400s - loss: 0.0191 - acc: 0.9941 - val_loss: 0.0124 - val_acc: 0.9968\n",
      "Epoch 19/30\n",
      " - 396s - loss: 0.0159 - acc: 0.9952 - val_loss: 0.0181 - val_acc: 0.9944\n",
      "Epoch 20/30\n",
      " - 396s - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0171 - val_acc: 0.9950\n",
      "Epoch 21/30\n",
      " - 408s - loss: 0.0165 - acc: 0.9948 - val_loss: 0.0203 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 22/30\n",
      " - 404s - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0137 - val_acc: 0.9956\n",
      "Epoch 23/30\n",
      " - 401s - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0136 - val_acc: 0.9964\n",
      "Epoch 24/30\n",
      " - 399s - loss: 0.0125 - acc: 0.9959 - val_loss: 0.0179 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 25/30\n",
      " - 399s - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0125 - val_acc: 0.9962\n",
      "Epoch 26/30\n",
      " - 399s - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0145 - val_acc: 0.9956\n",
      "Epoch 27/30\n",
      " - 400s - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0132 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 28/30\n",
      " - 401s - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0137 - val_acc: 0.9958\n",
      "Epoch 29/30\n",
      " - 402s - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0133 - val_acc: 0.9954\n",
      "Epoch 30/30\n",
      " - 402s - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0131 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n"
     ]
    }
   ],
   "source": [
    "kernel_size_arr=[5]\n",
    "ensemble_model=[]\n",
    "for i in kernel_size_arr:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters = 64, kernel_size = (i,i),padding = 'Same',use_bias=False, input_shape = (28,28,1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))                 \n",
    "    model.add(layers.Conv2D(filters = 64, kernel_size = (i,i),padding = 'Same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    # optimizer = RMSProp(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                patience=3, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.5, \n",
    "                                                min_lr=0.00001)\n",
    "    model.fit_generator(datagen.flow(train_data,train_labels, batch_size=64),\n",
    "                                epochs = 30, validation_data = (val_data,val_labels),\n",
    "                                verbose = 2, steps_per_epoch=train_data.shape[0] // 64\n",
    "                                , callbacks=[learning_rate_reduction])\n",
    "    # history = model.fit_generator(datagen.flow(train_data,train_labels, batch_size=64),\n",
    "    #                               epochs = 30, validation_data = (val_data,val_labels),\n",
    "    #                               verbose = 2, steps_per_epoch=train_data.shape[0] // 64\n",
    "    #                               , callbacks=[learning_rate_reduction])\n",
    "\n",
    "    ensemble_model.append(model)\n",
    "    model.save(\"model\"+str(i)+\".h5\")\n",
    "ensemble_model = np.array(ensemble_model)\n",
    "final_predictions = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calculate accuracy of ensemble via mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/harry/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "models loaded\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('model3.h5')\n",
    "model2 = load_model('model4.h5')\n",
    "model3 = load_model('model5.h5')\n",
    "ensemb = [model1,model2,model3]\n",
    "print('models loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy\n",
      "0.996128181893072\n",
      "Validation Loss\n",
      "0.003871818106928083\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_data)):\n",
    "    predictions = []\n",
    "    for model in ensemb:\n",
    "        predict = model.predict(np.array([val_data[i]]))\n",
    "        prediction = max(predict[0])\n",
    "        int_prediction = predict[0].tolist().index(prediction)\n",
    "        predictions.append(int_prediction)\n",
    "    most_votes = mode(predictions)\n",
    "    if val_labels[i][most_votes[0]]==1:\n",
    "        final_predictions.append(True)\n",
    "    else:\n",
    "        final_predictions.append(False)\n",
    "\n",
    "val_acc = final_predictions.count(True) / len(final_predictions)\n",
    "val_loss = final_predictions.count(False) / len(final_predictions)\n",
    "print('Validation Accuracy')\n",
    "print(val_acc)\n",
    "print('Validation Loss')\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could attempt to retrain the model on the entire dataset rather than split on validation data but considering my computer nearly died I think I'll settle for this score. I could also use a larger ensemble but I think I'll save my computer for a better competition. Time to predict the test data and send to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  1  2\n",
      "1  2  0\n",
      "2  3  9\n",
      "3  4  0\n",
      "4  5  3\n",
      "results are in!\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.empty((0,2),int)\n",
    "for i in range(len(test_data)):\n",
    "    predictions = []\n",
    "    for model in ensemb:\n",
    "        predict = model.predict(np.array([test_data[i]]))\n",
    "        prediction = max(predict[0])\n",
    "        int_prediction = predict[0].tolist().index(prediction)\n",
    "        predictions.append(int_prediction)\n",
    "    most_votes = mode(predictions)\n",
    "    test_predictions=np.append(test_predictions,np.array([[i+1,int(most_votes[0][0])]]),axis=0)\n",
    "    \n",
    "df = pd.DataFrame(data=test_predictions)\n",
    "print(df.head())\n",
    "print('results are in!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv',index=False, header=['ImageId','Label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondaf3e9afc952da4cb8ac0d3fa0ef5802f7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
